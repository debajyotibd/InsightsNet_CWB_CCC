.\" Automatically generated by Pod::Man 4.14 (Pod::Simple 3.42)
.\"
.\" Standard preamble:
.\" ========================================================================
.de Sp \" Vertical space (when we can't use .PP)
.if t .sp .5v
.if n .sp
..
.de Vb \" Begin verbatim text
.ft CW
.nf
.ne \\$1
..
.de Ve \" End verbatim text
.ft R
.fi
..
.\" Set up some character translations and predefined strings.  \*(-- will
.\" give an unbreakable dash, \*(PI will give pi, \*(L" will give a left
.\" double quote, and \*(R" will give a right double quote.  \*(C+ will
.\" give a nicer C++.  Capital omega is used to do unbreakable dashes and
.\" therefore won't be available.  \*(C` and \*(C' expand to `' in nroff,
.\" nothing in troff, for use with C<>.
.tr \(*W-
.ds C+ C\v'-.1v'\h'-1p'\s-2+\h'-1p'+\s0\v'.1v'\h'-1p'
.ie n \{\
.    ds -- \(*W-
.    ds PI pi
.    if (\n(.H=4u)&(1m=24u) .ds -- \(*W\h'-12u'\(*W\h'-12u'-\" diablo 10 pitch
.    if (\n(.H=4u)&(1m=20u) .ds -- \(*W\h'-12u'\(*W\h'-8u'-\"  diablo 12 pitch
.    ds L" ""
.    ds R" ""
.    ds C` ""
.    ds C' ""
'br\}
.el\{\
.    ds -- \|\(em\|
.    ds PI \(*p
.    ds L" ``
.    ds R" ''
.    ds C`
.    ds C'
'br\}
.\"
.\" Escape single quotes in literal strings from groff's Unicode transform.
.ie \n(.g .ds Aq \(aq
.el       .ds Aq '
.\"
.\" If the F register is >0, we'll generate index entries on stderr for
.\" titles (.TH), headers (.SH), subsections (.SS), items (.Ip), and index
.\" entries marked with X<> in POD.  Of course, you'll have to process the
.\" output yourself in some meaningful fashion.
.\"
.\" Avoid warning from groff about undefined register 'F'.
.de IX
..
.nr rF 0
.if \n(.g .if rF .nr rF 1
.if (\n(rF:(\n(.g==0)) \{\
.    if \nF \{\
.        de IX
.        tm Index:\\$1\t\\n%\t"\\$2"
..
.        if !\nF==2 \{\
.            nr % 0
.            nr F 2
.        \}
.    \}
.\}
.rr rF
.\" ========================================================================
.\"
.IX Title "CWB::CEQL 3pm"
.TH CWB::CEQL 3pm "2023-06-22" "perl v5.34.0" "User Contributed Perl Documentation"
.\" For nroff, turn off justification.  Always turn off hyphenation; it makes
.\" way too many mistakes in technical documents.
.if n .ad l
.nh
.SH "NAME"
CWB::CEQL \- The Common Elementary Query Language for CQP front\-ends
.SH "SYNOPSIS"
.IX Header "SYNOPSIS"
.Vb 1
\&  # end users: see section "CEQL SYNTAX" below for an overview of CEQL notation
\&
\&  use CWB::CEQL;
\&  our $CEQL = new CWB::CEQL;
\&
\&  # configuration settings (see METHODS section for details and default values)
\&  $CEQL\->SetParam("pos_attribute", "tag");          # p\-attribute for POS tags
\&  $CEQL\->SetParam("lemma_attribute", "lem");        # p\-attribute for lemmas
\&  $CEQL\->SetParam("simple_pos", \e%lookup_table);    # lookup table for simple POS
\&  $self\->SetParam("simple_pos_attribute", "class"); # p\-attribute for simple POS
\&  $self\->SetParam("s_attributes", {"s" => 1});      # s\-attributes allowed in CEQL queries
\&  $self\->SetParam("default_ignore_case", 1);        # if 1, default to case\-folded search
\&  $self\->SetParam("default_ignore_diac", 0);        # if 1, default to accent\-folded search
\&  $self\->SetParam("ignore_case", {"word_attribute" => 1, "lemma_attribute" => 1, ...}); # case/accent folding for individual attributes;
\&  $self\->SetParam("ignore_diac", {"word_attribute" => 1, "lemma_attribute" => 0, ...}); # keys are the strings for attribute parameters (above) plus "s_attributes"
\&  $self\->SetParam("tab_optimisation", 1);           # enable TAB query optimisation
\&
\&  $cqp_query = $CEQL\->Parse($ceql_query);
\&  if (not defined $cqp_query) {
\&    @error_msg = $CEQL\->ErrorMessage;
\&    $html_msg = $CEQL\->HtmlErrorMessage;
\&  }
\&  # $cqp_query can now be sent to CQP backend (e.g. with CWB::CQP module)
\&
\&  #### extend or modify standard CEQL grammar by subclassing ####
\&  package BNCWEB::CEQL;
\&  use base \*(AqCWB::CEQL\*(Aq;
\&
\&  sub lemma {
\&    ## overwrite \*(Aqlemma\*(Aq rule here (e.g. to allow for BNCweb\*(Aqs \`\`{bucket/N}\*(Aq\*(Aq notation)
\&    my $orig_result = $self\->SUPER::lemma($string); # call original rule if needed
\&  }
\&
\&  ## you can now use BNCWEB::CEQL in the same way as CWB::CEQL
.Ve
.SH ""
.IX Header ""
.SH "DESCRIPTION"
.IX Header "DESCRIPTION"
This module implements the core syntax of the \fBCommon Elementary Query Language\fR (\fB\s-1CEQL\s0\fR) as a \fB\s-1DPP\s0\fR grammar (see CWB::CEQL::Parser for details).
It can either be used directly, adjusting configuration settings with the \fBSetParam\fR method as required, or subclass \fB\s-1CWB::CEQL\s0\fR in order to modify and/or extend the grammar.  In the latter case, you are strongly advised not to change the meaning of core \s-1CEQL\s0 features, so that end-users can rely on the same familiar syntax in all CEQL-based Web interfaces.
.PP
A complete specification of the core \s-1CEQL\s0 syntax can be found in section \*(L"\s-1CEQL SYNTAX\*(R"\s0 below.  This is the most important part of the documentation for end users and can also be found online at <http://cwb.sf.net/ceql.php>.
.PP
Application developers can find an overview of relevant \s-1API\s0 methods and the available configuration parameters (\s-1CWB\s0 attributes for different linguistic annotations, default case/accent\-folding, etc.) in section \*(L"\s-1METHODS\*(R"\s0.
.PP
Section \*(L"\s-1EXTENDING CEQL\*(R"\s0 explains how to extend or customise \s-1CEQL\s0 syntax by subclassing \fB\s-1CWB::CEQL\s0\fR.  It is highly recommended to read the technical documentation in section \*(L"\s-1STANDARD CEQL RULES\*(R"\s0 and the source code of the \fB\s-1CWB::CEQL\s0\fR module.  Extended rules are most conveniently implemented as modified copies of the methods defined there.
.SH "CEQL SYNTAX"
.IX Header "CEQL SYNTAX"
A gentle tutorial-style introduction to \s-1CEQL\s0 syntax with many examples and exercises can be found in Chapter 6 (pp. 93\-117) of Hoffmann et al. (2008), \fICorpus Linguistics with BNCweb.\fR  A quick referenc with the most commonly used features of \s-1CEQL\s0 is included in the \fBCQPweb\fR user interfaces and can be accessed e.g. at <https://cqpweb.lancs.ac.uk/doc/cqpweb\-simple\-syntax\-help.pdf>.
.PP
The present document aims to give a complete and precise specification of the core \s-1CEQL\s0 grammar.
.SS "Wildcard Patterns"
.IX Subsection "Wildcard Patterns"
\&\s-1CEQL\s0 is based on wildcard patterns for matching word forms and annotations. A wildcard pattern by itself finds all tokens whose surface form matches the pattern. Wildcard patterns \fImust not contain blanks\fR or other whitespace.
.PP
The \fBbasic wildcards\fR are
.PP
.Vb 3
\&    ?    a single arbitrary character
\&    *    zero or more characters
\&    +    one or more characters
.Ve
.PP
These wildcards are often used for prefix or suffix searches, e.g. \f(CW\*(C`+able\*(C'\fR (all words ending in \*(L"\-able\*(R" except for the word \*(L"able\*(R" itself).  Clusters of wildcards specify a minimum number of characters, e.g. \f(CW\*(C`???*\*(C'\fR for 3 or more.
.PP
Most other characters match only themselves. However, all \s-1CEQL\s0 metacharacters (not just wildcards) must be \fBescaped\fR with a backslash \f(CW\*(C`\e\*(C'\fR to match the literal character (e.g. \f(CW\*(C`\e?\*(C'\fR to find a question mark).  The full set of metacharacters in the core \s-1CEQL\s0 grammar is
.PP
.Vb 1
\&    ? * + , : ! @ / ( ) [ ] { } _ \- < >
.Ve
.PP
Some of them are only interpreted as metacharacters in particular contexts.  It is safest, and recommended, to escape \fIevery\fR literal \s-1ASCII\s0 punctuation character with a backslash.
.PP
Groups of \fBalternatives\fR are separated by commas and enclosed in square brackets, e.g. \f(CW\*(C`[north,south,west,east]\*(C'\fR. They can include wildcards and an empty alternative can be appended to make the entire set optional (e.g. \f(CW\*(C`walk[s,ed,ing,]\*(C'\fR to match any form of the verb \*(L"walk\*(R").
.PP
Various \fBescape sequences\fR, consisting of a backslash followed by a letter, match specific sets and sequences of characters.  Escape sequences recognised by the core \s-1CEQL\s0 grammar are:
.PP
.Vb 10
\&    \ea   any single letter
\&    \eA   any sequence of letters (one or more)
\&    \el   any single lowercase letter
\&    \eL   any sequence of lowercase letters (one or more)
\&    \eu   any single uppercase letter
\&    \eU   any sequence of uppercase letters (one or more)
\&    \ed   any single digit
\&    \eD   any sequence of digits (one or more)
\&    \ew   a single "word" character (letter, number, apostrophe, hyphen)
\&    \eW   any sequence of "word" characters (one or more)
.Ve
.PP
The escape sequences are guaranteed to work correctly for \s-1UTF\-8\s0 encoded corpora, but may not be fully supported for legacy 8\-bit encodings (in which case they might only match \s-1ASCII\s0 letters and digits).
.PP
Wildcard patterns can be \fBnegated\fR with a leading exclamation mark \f(CW\*(C`!\*(C'\fR; a negated pattern finds any string that \fIdoes not\fR match the pattern.
.SS "Linguistic Annotation"
.IX Subsection "Linguistic Annotation"
\&\s-1CEQL\s0 queries provide access to three items of token-level annotation in addition to surface forms. They are described below as \fBlemma\fR, \fB\s-1POS\s0\fR (part-of-speech tag) and \fBsimple \s-1POS\s0\fR, which is the original intention. However, keep in mind that corpus search interfaces may be configured to access other annotation layers (say, semantic tags instead of simple \s-1POS\s0).
.PP
A \fBlemma\fR search is carried out by enclosing the wildcard pattern in curly braces, e.g. \f(CW\*(C`{go}\*(C'\fR.  All elements of the wildcard pattern described above must be enclosed in the braces, including negation (\f(CW\*(C`{!go}\*(C'\fR).  Note that word form and lemma constraints are mutually exclusive on the same token.
.PP
A single\-\fBtoken expression\fR in \s-1CEQL\s0 combines such a lexical constraint with a part-of-speech tag, separated by an underscore \f(CW\*(C`_\*(C'\fR.  The \s-1POS\s0 tag can either be matched directly with a wildcard pattern, or one of a pre-defined set of simple \s-1POS\s0 tags can be selected (in curly braces).  There are four possible combinations for a full token expression:
.PP
.Vb 4
\&    WORD_POS
\&    {LEMMA}_POS
\&    WORD_{Simple POS}
\&    {LEMMA}_{Simple POS}
.Ve
.PP
Keep in mind that \fB\s-1POS\s0 tags\fR may differ between corpora and make sure to read documentation on the respective tagset for successful \s-1POS\s0 searches.  Full \s-1POS\s0 constraints are wildcard patterns, which is convenient with complex tagsets.  In particular, the pattern can be negated, e.g. \f(CW\*(C`can_!MD\*(C'\fR to exclude the frequent modal reading of \fIcan\fR.  Also keep in mind that \fBsimple \s-1POS\s0 tags\fR are available only if they have been set up for the corpus at hand by an administrator.  Even though simple \s-1POS\s0 constraints aren't wildcard patterns, they can be negated (e.g. \f(CW\*(C`{walk}_{!V}\*(C'\fR).
.PP
The lexical constraint can be omitted in order to match a token only by its \s-1POS\s0 tag. Assuming the Penn treebank tagset and a simple \s-1POS\s0 tag \f(CW\*(C`A\*(C'\fR for adjectives, these four token expressions are fully equivalent:
.PP
.Vb 2
\&    _JJ*     *_JJ*
\&    _{A}     *_{A}
.Ve
.PP
Optional \fBmodifier flags\fR can be appended to each constraint: \f(CW\*(C`:c\*(C'\fR for case-insensitive matching, \f(CW\*(C`:d\*(C'\fR to ignore diacritics (Unicode combining marks, including all accents and umlauts) and \f(CW\*(C`:cd\*(C'\fR for both.  If an annotation defaults to case\- or diacritic-insensitive mode, this can be overridden with an uppercase modifier \f(CW\*(C`:C\*(C'\fR, \f(CW\*(C`:D\*(C'\fR or \f(CW\*(C`:CD\*(C'\fR.  (Mixed combinations are allowed, e.g. \f(CW\*(C`:Cd\*(C'\fR to override a case-insensitive default but ignore diacritics.)
Keep in mind that modifiers go \fIoutside\fR curly braces:
.PP
.Vb 1
\&    {fiancee}:cd_N*:C
.Ve
.SS "Phrase Queries"
.IX Subsection "Phrase Queries"
Phrase queries match \fBsequences of tokens\fR.  They consist of one or more token expressions separated by whitespace.  Note that the query has to match the tokenization conventions of the corpus at hand.  For example, a tag question (\*(L", isn't it?\*(R") is typically split into five tokens and can be found with the query
.PP
.Vb 1
\&    \e, is n\*(Aqt it \e?
.Ve
.PP
A single \f(CW\*(C`+\*(C'\fR stands for an \fBarbitrary token\fR, a single \f(CW\*(C`*\*(C'\fR for an optional token.  Multiple \f(CW\*(C`+\*(C'\fR and/or \f(CW\*(C`*\*(C'\fR can (and should) be bundled for a flexible number of tokens, e.g. \f(CW\*(C`++***\*(C'\fR for 2 to 5 arbitrary tokens.
.PP
\&\fBGroups\fR of tokens can be enclosed in round parentheses within a phrase query.  Such groups may contain \fBalternatives\fR delimited by pipe symbols (vertical bar, \f(CW\*(C`|\*(C'\fR):
.PP
.Vb 1
\&    it was ( ...A... | ...B... | ...C... )
.Ve
.PP
will find \*(L"it was\*(R" followed by a token sequence that matches either the phrase query A, the phrase query B or the phrase query C.  Empty alternatives are not allowed in this case.  Whitespace can be omitted after the opening parenthesis, around the pipe symbols and before the closing parenthesis.
.PP
A \fBquantifier\fR can be appended to the closing parenthesis of a group, whether or not it includes alternatives.  Note that there \fImust not\fR be any whitespace between the closing parenthesis and the quantifier (otherwise it would be interpreted as a separate token expression).  Quantifiers specify repetition of the group:
.PP
.Vb 7
\&    ( ... )?        0 or 1 (group is optional)
\&    ( ... )*        0 or more
\&    ( ... )+        1 or more
\&    ( ... ){N}      exactly N
\&    ( ... ){N,M}    between N and M
\&    ( ... ){N,}     at least N
\&    ( ... ){0,M}    at most M
.Ve
.PP
Groups can contain further subgroups with alternatives and quantification.  Note that group notation is needed to match an open-ended number of arbitrary tokens; it can also be more readable for finite ranges
.PP
.Vb 4
\&    (+)?            same as: *
\&    (+)*            any number of arbitrary tokens
\&    (+)+            at least one arbitary token
\&    (+){2,5}        same as: ++***
.Ve
.PP
You can think of the group \f(CW\*(C`(+)\*(C'\fR as a \fBmatchall\fR symbol for an arbitrary token.
.PP
A token expression can be marked as an \fBanchor point\fR with an initial \f(CW\*(C`@\*(C'\fR sign (for the \*(L"target\*(R" anchor). There must be no whitespace between the marker and the token expression.  Numbered anchors are set with \f(CW@0:\fR, \f(CW@1:\fR through \f(CW@9:\fR.  By default, \f(CW@0:\fR sets the \*(L"target\*(R" anchor and \f(CW@1:\fR sets the \*(L"keyword\*(R" anchor.  Further numbered anchors need special support from the \s-1GUI\s0 software executing the \s-1CEQL\s0 queries.
.PP
Use \fB\s-1XML\s0 tags\fR to match the start and end of a s\-attribute region, e.g. \f(CW\*(C`<s>\*(C'\fR for the start of a sentence and \f(CW\*(C`</s>\*(C'\fR for a sentence end.  Since such tags denote token boundaries rather than full tokens, a tag by itself is not a valid query: always specify at least one token expression.  A list of all \f(CW\*(C`<text>\*(C'\fR regions is obtained with
.PP
.Vb 1
\&    <text> +
.Ve
.PP
which matches the first token in each text.  A pair of corresponding start and end tags matches a complete s\-attribute region, e.g.
.PP
.Vb 1
\&    <quote> (+)+ </quote>
.Ve
.PP
a \f(CW\*(C`<quote>\*(C'\fR region containing an arbitary number of tokens (but keep in mind that \s-1CQP\s0 imposes limits on the number of tokens that can be matched, so very long quotations might not be found).
.PP
Attributes on \s-1XML\s0 start tags can be tested with the notation
.PP
.Vb 1
\&    <tag_attribute=PATTERN>
.Ve
.PP
where \f(CW\*(C`PATTERN\*(C'\fR is a wildcard pattern, possibly including negation and case/diacritic modifier flags.  It is a quirk of the underlying \s-1CQP\s0 query language that every \s-1XML\s0 tag annotation is represented as a separate s\-attribute following the indicated naming convention.  Therefore, multiple start tags must be specified in order to test several annotations.  Also keep in mind that an end tag with the same name is required for matching a full region. A named entity annotated in the input text as
.PP
.Vb 1
\&    ... <ne type="ORG" status="fictional">Sirius Cybernetics Corp.</ne> ...
.Ve
.PP
would be matched by the query
.PP
.Vb 1
\&    <ne_type=org:c> <ne_status=fict*> (+)+ </ne_type>
.Ve
.PP
Phrase queries can use different \fBmatching strategies\fR, selected by a modifier at the start of the query.  The default strategy (explicitly selected with \f(CW\*(C`(?standard)\*(C'\fR) includes optional elements at the start of the query, but uses non-greedy matching afterwards; in particular all optional elements at the end of the query are dropped.  In some cases, the \f(CW\*(C`(?longest)\*(C'\fR strategy can be useful to include such optional elements and enable greedy matching of quantifiers.  See the \s-1CQP\s0 Query Language Tutorial, Sec. 6.1 for details on matching strategies.
.SS "Proximity Queries"
.IX Subsection "Proximity Queries"
Proximity queries match \fBco-occurrence patterns\fR.  They also build on token expressions, but do not allow any of the constructions of phrase queries.  Instead, tokens are filtered based in their co-occurrence with other tokens.
There are six basic forms of co-occurrence tests:
.PP
.Vb 4
\&    A <<N>> B       B occurs within N tokens around A
\&    A <<N<< B       B occurs within N tokens to the left of A
\&    A >>N>> B       B occurs within N tokens to the right of A
\&    A <<REG>> B     A and B occur in the same region of s\-attribute REG
\&
\&    A <<K,N<< B     B occurs within N tokens to the left of A,
\&                    but at a distance of at least K tokens
\&    A >>K,N>> B     B occurs within N tokens to the right of A,
\&                    but at a distance of at least K tokens
.Ve
.PP
In each case, those occurrences of token expression A are returned which satisfy the constraint. The corresponding positions of B cannot be accessed in the query result.  As an example,
.PP
.Vb 1
\&   {bucket} <<s>> {kick}_V*
.Ve
.PP
would return all instances of the lemma \*(L"bucket\*(R" that occur in the same sentence as the verb \*(L"kick\*(R", but not the matching instances of \*(L"kick\*(R".
.PP
A and B can also be proximity queries themselves, using parentheses to determine the order of evaluation. As an example,
.PP
.Vb 1
\&    (A <<3<< B) <<s>> (C <<2>> D)
.Ve
.PP
finds all instances of A that are preceded by B (within 3 tokens to the left) and that also occur in the same sentence as a combination of C and D (within 2 tokens).  Proximity queries can be nested to arbitrary depth.
.PP
There are two special cases for sequences without parentheses:
.PP
.Vb 1
\&    A <<5>> B <<3<< C <<s>> D
.Ve
.PP
applies multiple tests to the instance of A, i.e. it is implicitly parenthesised as
.PP
.Vb 1
\&    ((A <<5>> B) <<3<< C) <<s>> D
.Ve
.PP
A sequence of token expressions without any co-occurrence specifiers in between is interpreted as neighbouring tokens, i.e.
.PP
.Vb 1
\&    out of {coin}
.Ve
.PP
is rewritten to
.PP
.Vb 1
\&    out >>1>> of >>2>> {coin}
.Ve
.PP
and therefore returns only the positions of \*(L"out\*(R".
.PP
Neither \s-1XML\s0 tags nor anchor points are supported by proximity queries.  Likewise, co-occurrence constraints cannot be negated, i.e. you cannot test for non-cooccurrence.
.SH "METHODS"
.IX Header "METHODS"
The following \s-1API\s0 methods are inherited from \fBCWB::CEQL::Parser\fR.  The explanations below focus on their application in a \s-1CEQL\s0 simple query frontend.  The documentation of \fBSetParam\fR includes a complete listing of available configuration parameters as well as their usage and default values.
.IP "\fI\f(CI$CEQL\fI\fR = \fBnew\fR \s-1CWB::CEQL\s0;" 4
.IX Item "$CEQL = new CWB::CEQL;"
Create parser object for \s-1CEQL\s0 queries.  Use the \fBParse\fR method of \fI\f(CI$CEQL\fI\fR
to translate a \s-1CEQL\s0 query into \s-1CQP\s0 code.
.IP "\fI\f(CI$cqp_query\fI\fR = \fI\f(CI$CEQL\fI\fR\->\fBParse\fR(\fI\f(CI$simple_query\fI\fR);" 4
.IX Item "$cqp_query = $CEQL->Parse($simple_query);"
Parses simple query in \s-1CEQL\s0 syntax and returns equivalent \s-1CQP\s0 code.  If there
is a syntax error in \fI\f(CI$simple_query\fI\fR or parsing fails for some other reason,
an \fBundef\fRined value is returned.
.ie n .IP "@text_lines = \fI\f(CI$CEQL\fI\fR\->\fBErrorMessage\fR;" 4
.el .IP "\f(CW@text_lines\fR = \fI\f(CI$CEQL\fI\fR\->\fBErrorMessage\fR;" 4
.IX Item "@text_lines = $CEQL->ErrorMessage;"
.PD 0
.ie n .IP "$html_code = \fI\f(CI$CEQL\fI\fR\->\fBHtmlErrorMessage\fR;" 4
.el .IP "\f(CW$html_code\fR = \fI\f(CI$CEQL\fI\fR\->\fBHtmlErrorMessage\fR;" 4
.IX Item "$html_code = $CEQL->HtmlErrorMessage;"
.PD
If the last \s-1CEQL\s0 query failed to parse, these methods return an error message
either as a list of text lines (\fBErrorMessage\fR) or as pre-formatted \s-1HTML\s0 code
that can be used directly by a Web interface (\fBHtmlErrorMessage\fR).  The error
message includes a backtrace of the internal call stack in order to help users
identify the precise location of the problem.
.IP "\fI\f(CI$CEQL\fI\fR\->\fBSetParam\fR(\fI\f(CI$name\fI\fR, \fI\f(CI$value\fI\fR);" 4
.IX Item "$CEQL->SetParam($name, $value);"
Change parameters of the \s-1CEQL\s0 grammar.  Currently, the following parameters
are available:
.RS 4
.ie n .IP """pos_attribute""" 4
.el .IP "\f(CWpos_attribute\fR" 4
.IX Item "pos_attribute"
The p\-attribute used to store part-of-speech tags in the \s-1CWB\s0 corpus (default:
\&\f(CW\*(C`pos\*(C'\fR).  \s-1CEQL\s0 queries should not be used for corpora without \s-1POS\s0 tagging,
which we consider to be a minimal level of annotation.
.ie n .IP """lemma_attribute""" 4
.el .IP "\f(CWlemma_attribute\fR" 4
.IX Item "lemma_attribute"
The p\-attribute used to store lemmata (base forms) in the \s-1CWB\s0 corpus (default:
\&\f(CW\*(C`lemma\*(C'\fR).  Set to \fBundef\fR if the corpus has not been lemmatised.
.ie n .IP """simple_pos""" 4
.el .IP "\f(CWsimple_pos\fR" 4
.IX Item "simple_pos"
Lookup table for simple part-of-speech tags (in \s-1CEQL\s0 constructions like
\&\f(CW\*(C`run_{N}\*(C'\fR).  Must be a hashref with simple \s-1POS\s0 tags as keys and \s-1CQP\s0 regular
expressions matching an appropriate set of standard \s-1POS\s0 tags as the
corresponding values.  The default value is \fBundef\fR, indicating that no
simple \s-1POS\s0 tags have been defined.  A very basic setup for the Penn
Treebank tag set might look like this:
.Sp
.Vb 5
\&  $CEQL\->SetParam("simple_pos", {
\&      "N" => "NN.*",   # common nouns
\&      "V" => "V.*",    # any verb forms
\&      "A" => "JJ.*",   # adjectives
\&    });
.Ve
.ie n .IP """simple_pos_attribute""" 4
.el .IP "\f(CWsimple_pos_attribute\fR" 4
.IX Item "simple_pos_attribute"
Simple \s-1POS\s0 tags may use a different p\-attribute than standard \s-1POS\s0 tags,
specified by the \f(CW\*(C`simple_pos_attribute\*(C'\fR parameter.  If it is set to \fBundef\fR
(default), the \f(CW\*(C`pos_attribute\*(C'\fR will be used for simplified \s-1POS\s0 tags as well.
.ie n .IP """s_attributes""" 4
.el .IP "\f(CWs_attributes\fR" 4
.IX Item "s_attributes"
Lookup table indicating which s\-attributes in the \s-1CWB\s0 corpus may be accessed
in \s-1CEQL\s0 queries (using the \s-1XML\s0 tag notation, e.g. \f(CW\*(C`<s>\*(C'\fR or \f(CW\*(C`</s>\*(C'\fR,
or as a distance operator in proximity queries, e.g. \f(CW\*(C`<<s>>\*(C'\fR).  The
main purpose of this table is to keep the \s-1CEQL\s0 parser from passing through
arbitrary tags to the \s-1CQP\s0 code, which might generate confusing error messages.
Must be a hashref with the names of valid s\-attributes as keys mapped to \s-1TRUE\s0
values.  The default setting only allows sentences or s\-unit, which should be
annotated in every corpus:
.Sp
.Vb 1
\&  $CEQL\->SetParam("s_attributes", { "s" => 1 });
.Ve
.ie n .IP """default_ignore_case""" 4
.el .IP "\f(CWdefault_ignore_case\fR" 4
.IX Item "default_ignore_case"
Indicates whether \s-1CEQL\s0 queries should perform case-insensitive matching for
word forms and lemmas (\f(CW\*(C`:c\*(C'\fR modifier), which can be overridden with an
explicit \f(CW\*(C`:C\*(C'\fR modifier.  By default, case-insensitive matching is activated,
i.e. \f(CW\*(C`default_ignore_case\*(C'\fR is set to 1.
.ie n .IP """default_ignore_diac""" 4
.el .IP "\f(CWdefault_ignore_diac\fR" 4
.IX Item "default_ignore_diac"
Indicates whether \s-1CEQL\s0 queries should ignore accents (\fIdiacritics\fR) for word
forms and lemmas (\f(CW\*(C`:d\*(C'\fR modifier), which can be overridden with an explicit
\&\f(CW\*(C`:D\*(C'\fR modifier.  By default, matching does \fInot\fR ignore accents,
i.e. \f(CW\*(C`default_ignore_diac\*(C'\fR is set to 0.
.ie n .IP """ignore_case""" 4
.el .IP "\f(CWignore_case\fR" 4
.IX Item "ignore_case"
Individual case-insensitivity settings for different attributes. The parameter
value is a hash with keys \f(CW\*(C`word_attribute\*(C'\fR, \f(CW\*(C`lemma_attribute\*(C'\fR, \f(CW\*(C`pos_attribute\*(C'\fR, 
\&\f(CW\*(C`simple_pos_attribute\*(C'\fR and \f(CW\*(C`s_attribute\*(C'\fR (for constraints on \s-1XML\s0 start tags), 
and values 0 or 1. If a key is not set in the hash, it defaults to 
\&\f(CW\*(C`default_ignore_case\*(C'\fR for \f(CW\*(C`word_attribute\*(C'\fR and \f(CW\*(C`lemma_attribute\*(C'\fR, 
and to 0 for all other attributes.
.Sp
Extensions of the \s-1CEQL\s0 grammar can set and use further keys of their own choosing
in the \f(CW\*(C`ignore_case\*(C'\fR and \f(CW\*(C`ignore_diac\*(C'\fR parameters.
.ie n .IP """ignore_diac""" 4
.el .IP "\f(CWignore_diac\fR" 4
.IX Item "ignore_diac"
Individual diacritic-insensitivity settings for different attributes. The parameter
value is a hash with keys \f(CW\*(C`word_attribute\*(C'\fR, \f(CW\*(C`lemma_attribute\*(C'\fR, \f(CW\*(C`pos_attribute\*(C'\fR, 
\&\f(CW\*(C`simple_pos_attribute\*(C'\fR and \f(CW\*(C`s_attribute\*(C'\fR, and values 0 or 1. If a key is not 
set in the hash, it defaults to \f(CW\*(C`default_ignore_diac\*(C'\fR for \f(CW\*(C`word_attribute\*(C'\fR and 
\&\f(CW\*(C`lemma_attribute\*(C'\fR, and to 0 for all other attributes.
.ie n .IP """tab_optimisation""" 4
.el .IP "\f(CWtab_optimisation\fR" 4
.IX Item "tab_optimisation"
Rewrite simple phrase searches (possibly with optional tokens, e.g. \f(CW\*(C`++***\*(C'\fR) as \f(CW\*(C`TAB\*(C'\fR
queries for much faster execution.
.Sp
Note that the \s-1TAB\s0 rewrite may not be fully equivalent to the original phrase query
in some corner cases. If there are optional gaps, it behaves similar to the standard
matching strategy. Therefore, \f(CW\*(C`tab_optimisation\*(C'\fR should be disabled if a different
matching strategy has been selected in \s-1CQP.\s0
.RE
.RS 4
.RE
.PP
See the CWB::CEQL::Parser manpage for more detailed information and further methods.
.SH "EXTENDING CEQL"
.IX Header "EXTENDING CEQL"
While the core \s-1CEQL\s0 syntax documented above already constitutes a fairly complex and powerful query language, \s-1CEQL\s0 is designed to be customized and extended.  Such \fB\s-1CEQL\s0 extensions\fR are implemented by subclassing the standard \s-1CEQL\s0 grammar.  They are typically provided as a separate Perl module file (\f(CW\*(C`.pm\*(C'\fR), but small ad-hoc extensions can also be included directly in a Perl script.
.PP
The basic template for a \s-1CEQL\s0 extension in a separate \f(CW\*(C`.pm\*(C'\fR file is as follows:
.PP
.Vb 2
\&    package My::CEQL;
\&    use base \*(AqCWB::CEQL\*(Aq;
\&   
\&    # override selected CEQL grammar rules here
\&   
\&    1;
.Ve
.PP
You can then \f(CW\*(C`use My::CEQL;\*(C'\fR in your Perl scripts in the same way as \fB\s-1CWB::CEQL\s0\fR.
.SS "Parameters"
.IX Subsection "Parameters"
If you want to define new grammar parameters or change the default parameter settings, your grammar has to provide a constructor method that calls the constructor of the base grammar, e.g.
.PP
.Vb 3
\&    sub new {
\&      my $class = shift;
\&      my $self = new CWB::CEQL;
\&   
\&      $self\->NewParam("word_attribute", "word");
\&      $self\->setParam("default_ignore_case", 0);
\&   
\&      return bless($self, $class);
\&    }
.Ve
.SS "Overriding Grammar Rules"
.IX Subsection "Overriding Grammar Rules"
The standard \s-1CEQL\s0 grammar is split into many small rules.  \s-1CEQL\s0 extensions are created by overriding individual rules completely.  Start by copying the relevant rule from the \fB\s-1CWB::CEQL\s0\fR source code into your \f(CW\*(C`.pm\*(C'\fR file, then modify it as required.  See CWB::CEQL::Parser for details on how to write grammar rules.  All rules of the standard \s-1CEQL\s0 grammar are listed in section \*(L"\s-1STANDARD CEQL RULES\*(R"\s0 below with short descriptions of their function and purpose.
.PP
For example, in order to make the word form attribute configurable (say, in a social medial corpus that has original and normalized spellings) with the \f(CW\*(C`word_attribute\*(C'\fR parameter introduced above, you would have to override the \fBwordform_pattern\fR rule.  Copy the original rule into your grammar and modify it as follows:
.PP
.Vb 6
\&    sub wordform_pattern {
\&      my ($self, $wf) = @_;
\&      my $test = $self\->Call("negated_wildcard_pattern", $wf);
\&      my $word_att = $self\->GetParam("word_attribute"); # <\-\- NEW
\&      return $word_att.$test;                           # <\-\- MODIFIED
\&    }
.Ve
.PP
In some cases, it is easier to implement a wrapper than copy the full code of a complex grammar rule. This wrapper has to override the existing rule (otherwise all methods calling the rule would have to be changed), but will call into the base clase method.  An example is the wrapper below, which extends the \fBwildcard_pattern\fR rule to allow full character-level regular expressions (delimited by \f(CW\*(C`/.../\*(C'\fR).
.PP
.Vb 11
\&    sub wildcard_pattern {
\&      my ($self, $input) = @_;
\&      if ($input =~ m{^/(.+)/$}) {
\&        my $regexp = $1;
\&        $regexp =~ s/"/""/g; # escape double quotes
\&        return "\e"$regexp\e"";
\&      }
\&      else {
\&        return $self\->SUPER::wildcard_pattern($input);
\&      }
\&     }
.Ve
.SH "STANDARD CEQL RULES"
.IX Header "STANDARD CEQL RULES"
.ie n .IP """ceql_query""" 4
.el .IP "\f(CWceql_query\fR" 4
.IX Item "ceql_query"
.PD 0
.ie n .IP """default""" 4
.el .IP "\f(CWdefault\fR" 4
.IX Item "default"
.PD
The default rule of \fB\s-1CWB::CEQL\s0\fR is \f(CW\*(C`ceql_query\*(C'\fR.  After sanitising
whitespace, it uses a heuristic to determine whether the input string is a
\&\fBphrase query\fR or a \fBproximity query\fR and delegates parsing to the
appropriate rule (\f(CW\*(C`phrase_query\*(C'\fR or \f(CW\*(C`proximity_query\*(C'\fR).
.SS "Phrase Query"
.IX Subsection "Phrase Query"
.ie n .IP """phrase_query""" 4
.el .IP "\f(CWphrase_query\fR" 4
.IX Item "phrase_query"
A phrase query is the standard form of \s-1CEQL\s0 syntax.  It matches a single token
described by constraints on word form, lemma and/or part-of-speech tag, a
sequence of such tokens, or a complex lexico-grammatical pattern.  The
\&\f(CW\*(C`phrase_query\*(C'\fR rule splits its input into whitespace-separated token
expressions, \s-1XML\s0 tags and metacharacters such as \f(CW\*(C`(\*(C'\fR, \f(CW\*(C`)\*(C'\fR and \f(CW\*(C`|\*(C'\fR.  Then it
applies the \f(CW\*(C`phrase_element\*(C'\fR rule to each item in turn, and concatenates the
results into the complete \s-1CQP\s0 query.  The phrase query may start with an embedded
modifier such as \f(CW\*(C`(?longest)\*(C'\fR to change the matching strategy.
.ie n .IP """phrase_element""" 4
.el .IP "\f(CWphrase_element\fR" 4
.IX Item "phrase_element"
A phrase element is either a token expression (delegated to rule
\&\f(CW\*(C`token_expression\*(C'\fR), a \s-1XML\s0 tag for matching structure boundaries (delegated
to rule \f(CW\*(C`xml_tag\*(C'\fR), sequences of arbitrary (\f(CW\*(C`+\*(C'\fR) or skipped (\f(CW\*(C`*\*(C'\fR) tokens,
or a phrase-level metacharacter (the latter two are handled by the
\&\f(CW\*(C`phrase_element\*(C'\fR rule itself).  Proper nesting of parenthesised groups is
automatically ensured by the parser.
.Sp
Token expressions can be preceded by \f(CW\*(C`@\*(C'\fR to set a target marker, or \f(CW@0:\fR 
through \f(CW@9:\fR to set a numbered target marker.
.ie n .IP """xml_tag""" 4
.el .IP "\f(CWxml_tag\fR" 4
.IX Item "xml_tag"
A start or end tag matching the boundary of an s\-attribute region. The
\&\f(CW\*(C`xml_tag\*(C'\fR rule performs validation, in particularly ensuring that the
region name is listed as an allowed s\-attribute in the parameter
\&\f(CW\*(C`s_attributes\*(C'\fR, then passes the tag through to the \s-1CQP\s0 query.
.Sp
For a start tag, an optional wildcard pattern constraint may be specified
in the form \f(CW\*(C`<\f(CItag\f(CW=\f(CIpattern\f(CW>\*(C'\fR. The parser does not check whether
the selected s\-attribute in fact has annotations. If \f(CW\*(C`\f(CIpattern\f(CW\*(C'\fR starts with
\&\f(CW\*(C`!\*(C'\fR, the constraint is negated; case/diacritic\-sensitivity flags (\f(CW\*(C`:c\*(C'\fR etc.)
can be appended to the pattern, before the closing \f(CW\*(C`>\*(C'\fR.
.SS "Proximity Query"
.IX Subsection "Proximity Query"
.ie n .IP """proximity_query""" 4
.el .IP "\f(CWproximity_query\fR" 4
.IX Item "proximity_query"
A proximity query searches for combinations of words within a certain distance
of each other, specified either as a number of tokens (\fInumeric distance\fR) or
as co-occurrence within an s\-attribute region (\fIstructural distance\fR).  The
\&\f(CW\*(C`proximity_query\*(C'\fR rule splits its input into a sequence of token patterns,
distance operators and parentheses used for grouping.  Shorthand notation for
word sequences is expanded (e.g. \f(CW\*(C`as long as\*(C'\fR into \f(CW\*(C`as >>1>> long >>2>>
as\*(C'\fR), and then the \f(CW\*(C`proximity_expression\*(C'\fR rule is applied to each item in
turn.  A shift-reduce algorithm in \f(CW\*(C`proximity_expression\*(C'\fR reduces the
resulting list into a single \s-1CQP\s0 query (using the \*(L"\s-1MU\*(R"\s0 notation).
.ie n .IP """proximity_expression""" 4
.el .IP "\f(CWproximity_expression\fR" 4
.IX Item "proximity_expression"
A proximity expression is either a token expression (delegated to
\&\f(CW\*(C`token_expression\*(C'\fR), a distance operator (delegated to \f(CW\*(C`distance_operator\*(C'\fR)
or a parenthesis for grouping subexpressions (handled directly).  At each
step, the current result list is examined to check whether the respective type
of proximity expression is valid here.  When 3 elements have been collected in
the result list (term, operator, term), they are reduced to a single term.
This ensures that the \fBApply\fR method in \f(CW\*(C`proximity_query\*(C'\fR returns only a
single string containing the (almost) complete \s-1CQP\s0 query.
.ie n .IP """distance_operator""" 4
.el .IP "\f(CWdistance_operator\fR" 4
.IX Item "distance_operator"
A distance operator specifies the allowed distance between two tokens or
subexpressions in a proximity query.  Numeric distances are given as a number
of tokens and can be two-sided (\f(CW\*(C`<<n>>\*(C'\fR) or one-sided (\f(CW\*(C`<<n<<\*(C'\fR
to find the second term to the left of the first, or \f(CW\*(C`>>n>>\*(C'\fR to find it
to the right).  Structural distances are always two-sided and specifies an
s\-attribute region, in which both items must co-occur (e.g. \f(CW\*(C`<<s>>\*(C'\fR).
.SS "Token Expression"
.IX Subsection "Token Expression"
.ie n .IP """token_expression""" 4
.el .IP "\f(CWtoken_expression\fR" 4
.IX Item "token_expression"
Evaluate complete token expression with word form (or lemma) constraint and or
part-of-speech (or simple \s-1POS\s0) constraint.  The two parts of the token
expression are passed on to \f(CW\*(C`word_or_lemma_constraint\*(C'\fR and \f(CW\*(C`pos_constraint\*(C'\fR,
respectively.  This rule returns a \s-1CQP\s0 token expression enclosed in square
brackets.
.SS "Word Form / Lemma"
.IX Subsection "Word Form / Lemma"
.ie n .IP """word_or_lemma_constraint""" 4
.el .IP "\f(CWword_or_lemma_constraint\fR" 4
.IX Item "word_or_lemma_constraint"
Evaluate complete word form (without curly braces) or lemma constraint (in curly braces,
or with alternative \f(CW\*(C`%\*(C'\fR marker appended), including case/diacritic flags,
and return a single \s-1CQP\s0 constraint with appropriate \f(CW%c\fR and \f(CW%d\fR flags.
.ie n .IP """wordform_pattern""" 4
.el .IP "\f(CWwordform_pattern\fR" 4
.IX Item "wordform_pattern"
Translate wildcard pattern for word form into \s-1CQP\s0 constraint (using the
default \f(CW\*(C`word\*(C'\fR attribute).
.ie n .IP """lemma_pattern""" 4
.el .IP "\f(CWlemma_pattern\fR" 4
.IX Item "lemma_pattern"
Translate wildcard pattern for lemma into \s-1CQP\s0 constraint, using the
appropriate p\-attribute for base forms (given by the parameter
\&\f(CW\*(C`lemma_attribute\*(C'\fR).
.SS "Parts of Speech"
.IX Subsection "Parts of Speech"
.ie n .IP """pos_constraint""" 4
.el .IP "\f(CWpos_constraint\fR" 4
.IX Item "pos_constraint"
Evaluate a part-of-speech constraint (either a \f(CW\*(C`pos_tag\*(C'\fR or \f(CW\*(C`simple_pos\*(C'\fR),
returning suitable \s-1CQP\s0 code to be included in a token expression.
.ie n .IP """pos_tag""" 4
.el .IP "\f(CWpos_tag\fR" 4
.IX Item "pos_tag"
Translate wildcard pattern for part-of-speech tag into \s-1CQP\s0 constraint, using
the appropriate p\-attribute for \s-1POS\s0 tags (given by the parameter
\&\f(CW\*(C`pos_attribute\*(C'\fR).
.ie n .IP """simple_pos""" 4
.el .IP "\f(CWsimple_pos\fR" 4
.IX Item "simple_pos"
Translate simple part-of-speech tag into \s-1CQP\s0 constraint.  The specified tag is
looked up in the hash provided by the \f(CW\*(C`simple_pos\*(C'\fR parameter, and replaced by
the regular expression listed there.  If the tag cannot be found, or if no simple
tags have been defined, a helpful error message is generated.
.SS "Wildcard Patterns"
.IX Subsection "Wildcard Patterns"
.ie n .IP """negated_wildcard_pattern""" 4
.el .IP "\f(CWnegated_wildcard_pattern\fR" 4
.IX Item "negated_wildcard_pattern"
Wildcard pattern with optional negation (leading \f(CW\*(C`!\*(C'\fR). Returns quoted regular expression
preceded by appropriate \s-1CQP\s0 comparison operator (\f(CW\*(C`=\*(C'\fR or \f(CW\*(C`!=\*(C'\fR).
.Sp
For backward compatibility, the pattern \f(CW\*(C`!\*(C'\fR is interpreted as a literal exclamation mark.
.ie n .IP """wildcard_pattern""" 4
.el .IP "\f(CWwildcard_pattern\fR" 4
.IX Item "wildcard_pattern"
Translate string containing wildcards into regular expression, which is
enclosed in double quotes so it can directly be interpolated into a \s-1CQP\s0 query.
.Sp
Internally, the input string is split into wildcards and literal substrings,
which are then processed one item at a time with the \f(CW\*(C`wildcard_item\*(C'\fR
rule.
.ie n .IP """wildcard_item""" 4
.el .IP "\f(CWwildcard_item\fR" 4
.IX Item "wildcard_item"
Process an item of a wildcard pattern, which is either some metacharacter
(handled directly) or a literal substring (delegated to the \f(CW\*(C`literal_string\*(C'\fR
rule).  Proper nesting of alternatives is ensured using the shift-reduce
parsing mechanism (with \fBBeginGroup\fR and \fBEndGroup\fR calls).
.ie n .IP """literal_string""" 4
.el .IP "\f(CWliteral_string\fR" 4
.IX Item "literal_string"
Translate literal string into regular expression, escaping all metacharacters
with backslashes (backslashes in the input string are removed first).
.SS "Internal Subroutines"
.IX Subsection "Internal Subroutines"
.IP "(\fI\f(CI$has_empty_alt\fI\fR, \fI\f(CI@tokens\fI\fR) = \fI\f(CI$self\fI\fR\->\fB_remove_empty_alternatives\fR(\fI\f(CI@tokens\fI\fR);" 4
.IX Item "($has_empty_alt, @tokens) = $self->_remove_empty_alternatives(@tokens);"
This internal method identifies and removes empty alternatives from a
tokenised group of alternatives (\fI\f(CI@tokens\fI\fR), with alternatives separated by
\&\f(CW\*(C`|\*(C'\fR tokens.  In particular, leading and trailing separator tokens are removed,
and multiple consecutive separators are collapsed to a single \f(CW\*(C`|\*(C'\fR.  The first
return value (\fI\f(CI$has_empty_alt\fI\fR) indicates whether one or more empty
alternatives were found; it is followed by the sanitised list of tokens.
.IP "(\fI\f(CI$input\fI\fR, \fI\f(CI$flags\fI\fR) = \fI\f(CI$self\fI\fR\->\fB_parse_constraint_flags\fR(\fI\f(CI$input\fI\fR);" 4
.IX Item "($input, $flags) = $self->_parse_constraint_flags($input);"
.PD 0
.IP "\fI\f(CI$cqp_flags\fI\fR = \fI\f(CI$self\fI\fR\->\fB_apply_constraint_flags\fR(\fI\f(CI$flags\fI\fR, \fI\f(CI$attribute\fI\fR);" 4
.IX Item "$cqp_flags = $self->_apply_constraint_flags($flags, $attribute);"
.PD
Match flags \f(CW\*(C`:c\*(C'\fR, \f(CW\*(C`:C\*(C'\fR, \f(CW\*(C`:d\*(C'\fR and \f(CW\*(C`:D\*(C'\fR at end of subexpression, to turn case and/or diacritic insensitivity
on or off (overriding the default settings for attribute type \fI\f(CI$attribute\fI\fR).
.Sp
\&\fB_parse_constraint_flags\fR Returns \fI\f(CI$input\fI\fR with any flags removed and the \s-1CEQL\s0 flags as \fI\f(CI$flags\fI\fR.
\&\fB_apply_constraint_flags\fR takes \fI\f(CI$flags\fI\fR and the attribute type \fI\f(CI$attribute\fI\fR, and returns corresponding
\&\s-1CQP\s0 flags (\f(CW%c\fR, \f(CW%d\fR, \f(CW%cd\fR or an empty string) taking the appropriate defaults into account.
.Sp
The second parameter is an attribute \s-1TYPE,\s0 i.e. one of \*(L"word_attribute\*(R", \*(L"lemma_attribute\*(R", \*(L"pos_attribute\*(R",
\&\*(L"simple_pos_attribute\*(R", \*(L"s_attributes\*(R" \- not the actual name of an attribute.
.Sp
This operation hasn't been implemented as a grammar rule because it does not fit the paradigm of
taking a single input string and returning a \s-1CQP\s0 translation of the input.  It had to be split into
two separate methods because in many cases, the attribute type can only be determined after further
processing of \fI\f(CI$input\fI\fR.
.SH "COPYRIGHT"
.IX Header "COPYRIGHT"
Copyright (C) 2005\-2022 Stephanie Evert [https://purl.org/stephanie.evert]
.PP
This software is provided \s-1AS IS\s0 and the author makes no warranty as to
its use and performance. You may use the software, redistribute and
modify it under the same terms as Perl itself.
